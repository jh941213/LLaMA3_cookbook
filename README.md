# LLaMA3_Cookbook ğŸ¦™âœ¨
![d](https://github.com/jh941213/LLaMA3_cookbook/assets/112835087/98debd51-2697-45b9-b349-175349f2a407)


LLaMA3 (Large Language Model by META AI)ëŠ” AI ê¸°ìˆ ì˜ ìµœì „ì„ ì—ì„œ í™œì•½í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ğŸŒŸ ì´ ì €ì¥ì†ŒğŸ“ëŠ” LLaMA3ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ğŸš€ë¥¼ ì‹œì‘í•˜ëŠ” ë° í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ ì í•©ë‹ˆë‹¤.


## [ğŸ“œIntroducing Meta Llama 3: The most capable openly available LLM to date ë¦¬ë·° ](https://hyun941213.tistory.com/entry/Introducing-Meta-Llama-3-The-most-capable-openly-available-LLM-to-date-%EB%A6%AC%EB%B7%B0)

## ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë° ì •ë³´ ğŸŒ
- [ê³µì‹ í™ˆí˜ì´ì§€ ğŸ ](https://llama.meta.com/)
- [ì ‘ê·¼ ìš”ì²­ ğŸ“¬](https://llama.meta.com/llama-downloads/)
- [Meta Llama Model ì¹´ë“œ ğŸ´](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3)
- [Kaggle Meta ğŸ…](https://www.kaggle.com/organizations/metaresearch/models)

## âš¡ï¸ Cloud API 
### API í˜¸ì¶œ ê°€ëŠ¥ ğŸ”Œ
| ì´ë¦„          | ì„¤ëª…                                                              | ë§í¬ |
|--------------|-------------------------------------------------------------------|-----|
| Grok         | ê³ ì„±ëŠ¥ AI Chipì„ í†µí•´ LLaMA3 ì¸í¼ëŸ°ìŠ¤ ë° API í˜¸ì¶œ ê°€ëŠ¥            | [Grok ğŸŒ](https://console.groq.com/playground) |
| AWS          | Bedrockì—ì„œ LLaMA ì§€ì›, í˜„ì¬ëŠ” Llama2ë§Œ ì‚¬ìš© ê°€ëŠ¥                  | [AWS ğŸŒ](https://aws.amazon.com/ko/bedrock/) |
| Azure        | Microsoft Azureì—ì„œ 8B/70B ëª¨ë¸ ì§€ì›, Azure Marketplaceì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥ | [Azure ğŸŒ](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-8b-chat-offer?tab=overview)|
| GCP| Google Cloud Vertax AI ì—ì„œ ì‚¬ìš© ê°€ëŠ¥ | [GCP ğŸŒ](https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama3?_ga=2.164398141.-384541959.1712575317)
| together.ai  | Llama2, CodeLlama, Llama3 8b/70b ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥                | [together.ai ğŸŒ](https://www.together.ai/) |
| replicate    | Llama3 API ì§€ì› (Node.js, Python, HTTP)                            | [replicate ğŸŒ](https://replicate.com/blog/run-llama-3-with-an-api) |
| llama AI    | Llama3 8B/70B ì§€ì›, ë‹¤ë¥¸ OpenLLM ì§€ì›                         | [llama AI ğŸŒ](https://www.llama-api.com/) |
| Meta AI(github) | meta AI api ì—°ê²° | [MetaAI ğŸŒ](https://github.com/Strvm/meta-ai-api?tab=readme-ov-file)|


## ğŸ¤– ì¸í¼ëŸ°ìŠ¤ (Inference) ğŸ§ 

### ì¸í¼ëŸ°ìŠ¤ í”Œë«í¼ ğŸ–¥ï¸
| í”Œë«í¼ ì´ë¦„   | ì„¤ëª…                               | ë§í¬ |
|--------------|------------------------------------|-----|
| HuggingFace  | Llama 8B ëª¨ë¸                      | [Link ğŸŒ](https://meta-llama/Meta-Llama-3-8B) |
| HuggingFace  | Llama 70B ëª¨ë¸                     | [Link ğŸŒ](https://huggingface.co/meta-llama/Meta-Llama-3-70B) |
| HuggingFace  | Llama 8B Instruct ëª¨ë¸             | [Link ğŸŒ](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) |
| HuggingFace  | Llama 70B Instruct ëª¨ë¸            | [Link ğŸŒ](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) |
| HuggingFace  | Llama Guard-2-8B(ì •ì±…ëª¨ë¸)         | [Link ğŸŒ](https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B) |
| HuggingFace | Llama 8B KO (made beomi) | [Link ğŸŒ](https://huggingface.co/beomi/Llama-3-Open-Ko-8B-preview)|
| Ollama       | ë‹¤ì–‘í•œ ê²½ëŸ‰í™”ëœ Llama3 ëª¨ë¸ ì¸í¼ëŸ°ìŠ¤ ê°€ëŠ¥ | [Link ğŸŒ](https://ollama.com/library/llama3) |

### HuggingFace ëª¨ë¸ ğŸ¥
| ì´ë¦„   | ì„¤ëª…                               | ë§í¬ |
|--------------|----------------------------|-----|
|cognitivecomputations/dolphin-2.9-llama3-8b| ë¬´ê²€ì—´ íŒŒì¸íŠœë‹ | [Link ğŸŒ](https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b)|
|McGill-NLP/Llama-3-8B-Web| ì œë¡œìƒ· ì¸í„°ë„· ë§í¬ ì„ íƒ ëŠ¥ë ¥ |[Link ğŸŒ](https://huggingface.co/McGill-NLP/Llama-3-8B-Web)
## ğŸ’¬ Chat Interface (Related Information) ğŸ’»
| ì´ë¦„              | ë§í¬ |
|-----------------|-----|
| HuggingChat     | [Link ğŸŒ](https://huggingface.co/chat/) |
| Groq            | [Link ğŸŒ](https://groq.com/) |
| together.ai     | [Link ğŸŒ](https://www.together.ai/) |
| replicate Llama chat(local) | [Link ğŸŒ](https://github.com/replicate/llama-chat)|
| perplexity.ai(ê²½ëŸ‰í™”ëª¨ë¸) | [Link ğŸŒ](https://labs.perplexity.ai/)|
|openrouter.ai| [Link ğŸŒ](https://openrouter.ai/playground?models=meta-llama/llama-3-70b-instruct)|
| MetaAI (í•œêµ­ ì‚¬ìš©ë¶ˆê°€)|[Link ğŸŒ](https://www.meta.ai/)|
| Morphic(ë©€í‹°ëª¨ë‹¬ì œê³µ) | [Link ğŸŒ](https://www.morphic.sh/)|

## LLaMA Framework  ğŸ“˜
| ì´ë¦„       |ìœ í˜•| ë§í¬ 
|----------|-----|-----|
| Langchain | RAG | [Link ğŸŒ](https://www.langchain.com/) |
| llamaindex| RAG | [Link ğŸŒ](https://www.llamaindex.ai/) |
| llama.cpp| convert | [Link ğŸŒ](https://github.com/ggerganov/llama.cpp) |

## ğŸ› ï¸ íŒŒì¸íŠœë‹ (Fine-tuning) ğŸ”§
| ì´ë¦„      | ë§í¬ |
|---------|-----|
| Meta | [Link ğŸŒ](https://llama.meta.com/docs/how-to-guides/fine-tuning/)
| torchrune| [Link ğŸŒ](https://github.com/pytorch/torchtune)|
| LLaMAFactory| [Link ğŸŒ](https://github.com/hiyouga/LLaMA-Factory)|
|axolotl| [Link ğŸŒ](https://github.com/OpenAccess-AI-Collective/axolotl)|



## LLAMA3_Cookbook ğŸ‘©â€ğŸ³
| ì •ë³´                               | ë§í¬ |
|----------------------------------|-----|
| í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ           | [Link ğŸŒ](https://www.promptingguide.ai/tools)|
| WEB UI ë¥¼ ì‚¬ìš©í•´ì„œ llama3 ì‚¬ìš© | [Link ğŸŒ](https://dev.to/timesurgelabs/how-to-run-llama-3-locally-with-ollama-and-open-webui-297d) |
| API with Ollama, LangChain and ChromaDB with Flask API and PDF upload | [Link ğŸŒ](https://www.youtube.com/watch?v=7VAs22LC7WE) |
| ë§¥ë¶ê´€ë ¨ Llama íŠœë‹ ë° ì¸í¼ëŸ°ìŠ¤ ê°€ì´ë“œ | [Link ğŸŒ](https://itnext.io/step-by-step-guide-to-running-latest-llm-model-meta-llama-3-on-apple-silicon-macs-m1-m2-or-m3-b9424ada6840) | 
| Fine-tune Llama 3 with ORPO | [Link ğŸŒ](https://huggingface.co/blog/mlabonne/orpo-llama-3)|
| Qlora_aplaca_llama3 finetune | [Link ğŸŒ](https://colab.research.google.com/drive/1mPw6P52cERr93w3CMBiJjocdTnyPiKTX#scrollTo=6bZsfBuZDeCL)
| fully local RAG agents with LLama3 | [Link ğŸŒ](https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb) |
| RAG Chatbot LLama3(HF) | [Link ğŸŒ](https://huggingface.co/blog/not-lain/rag-chatbot-using-llama3) |
| llama index RAG llama3 | [Link ğŸŒ](https://lightning.ai/lightning-ai/studios/rag-using-llama-3-by-meta-ai) |
| ollama RAG + UI(Gradio) | [Link ğŸŒ](https://mer.vin/2024/04/llama-3-rag-using-ollama/) |

## LLM Dataset ğŸ—‚ï¸
| ì •ë³´                               | ë§í¬ |
|----------------------------------|-----|


## LLM skills ğŸ“Œ
| ì •ë³´                               | ë§í¬ |
|----------------------------------|-----|
|FSDP+QLORA finetunning | [Link ğŸŒ](https://github.com/AnswerDotAI/fsdp_qlora)|


## MAC vs 4090 ë¹„êµ ğŸ–¥ï¸ğŸ†šğŸ–¥ï¸
| í•­ëª©          | M3 Max                              | M1 Pro                    | RTX 4090                                    |
|---------------|-------------------------------------|---------------------------|---------------------------------------------|
| CPU ì½”ì–´      | 16ì½”ì–´                              | 10ì½”ì–´                    | 16ì½”ì–´ AMD                                  |
| ë©”ëª¨ë¦¬        | 128GB                               | 16GB    /32GB                  | 32GB                                        |
| GPU ë©”ëª¨ë¦¬    | 16ì½”ì–´ CPU ë° 40ì½”ì–´ GPU, 400GB/s ë©”ëª¨ë¦¬ ëŒ€ì—­í­                           |16ì½”ì–´ CPU ë° 40ì½”ì–´ GPU, 400GB/s ë©”ëª¨ë¦¬ ëŒ€ì—­í­                     | 24GB                                        |
| **ëª¨ë¸ 7B**   | - ëª¨ë“  ì»´í“¨í„°ì—ì„œ ì˜ ì‘ë™           | - ëª¨ë“  ì»´í“¨í„°ì—ì„œ ì˜ ì‘ë™ | - ëª¨ë“  ì»´í“¨í„°ì—ì„œ ì˜ ì‘ë™,ì„±ëŠ¥ M3 Maxì™€ ìœ ì‚¬                  |
| **ëª¨ë¸ 13B**  | - ì„±ëŠ¥ ì¢‹ìŒ                         | - ì„¸ ë²ˆì§¸ë¡œ ì„±ëŠ¥ ì¢‹ìŒ     | - ê°€ì¥ ì„±ëŠ¥ ì¢‹ìŒ                            |
| **ëª¨ë¸ 70B**  | - ë¹ ë¥´ê²Œ ì‹¤í–‰, 128GB ë©”ëª¨ë¦¬ í™œìš©    | - 16GB ë¶€ì¡±, í¬ë˜ì‹œ ë° ì¬ë¶€íŒ… | - GPUì—ì„œ ì‹¤í–‰ ë¶ˆê°€, CPUì—ì„œ ë§¤ìš° ëŠë¦¬ê²Œ ì‹¤í–‰ |
| ê²½ëŸ‰í™” ì—¬ë¶€   | ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë‹¤ë©´ í•˜ì§€ ì•Šì•„ë„ ë¨ | í•´ì•¼í•  ë“¯ í•¨ | Quantization íƒ€í˜‘ì„ í•´ì•¼í•¨ |
| ì „ë ¥ ì†Œëª¨      | 65W                                |                           | 250-300W                                    |
| ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ | ìš°ìˆ˜ ($4600)                       |                           | ë¹„êµì  ë‚®ìŒ ($6000 for A6000 GPU)           |

## ğŸ™Œ ê¸°ì—¬í•˜ê¸° ğŸ’–
ì´ ì €ì¥ì†Œì— ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? [Issues](https://github.com/your-github/LLaMA3_Recipes/issues)ì— ììœ ë¡­ê²Œ ì˜ê²¬ì„ ë‚¨ê¸°ê±°ë‚˜ Pull Requestë¥¼ ë³´ë‚´ì£¼ì„¸ìš”. ëª¨ë“  ì¢…ë¥˜ì˜ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

## ğŸ“© ë¬¸ì˜í•˜ê¸° ğŸ’Œ
ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ í˜‘ë ¥ì„ í¬ë§í•˜ì‹œëŠ” ë¶„ì€ [ì—¬ê¸°](https://github.com/your-github/LLaMA3_Recipes)ë¥¼ í´ë¦­í•˜ì—¬ ì €ì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”. í•¨ê»˜ ì§€ì‹ì„ ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤!

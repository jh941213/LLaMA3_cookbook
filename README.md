# LLaMA3_Cookbook ğŸ¦™

LLaMA3 (Large Language Model by META AI)ëŠ” AI ê¸°ìˆ ì˜ ìµœì „ì„ ì—ì„œ í™œì•½í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.ğŸŒŸ ì´ ì €ì¥ì†ŒğŸ“ëŠ” LLaMA3ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ğŸš€ë¥¼ ì‹œì‘í•˜ëŠ” ë° í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ ì í•©ë‹ˆë‹¤.

## ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë° ì •ë³´
- [ê³µì‹í™ˆí˜ì´ì§€](https://llama.meta.com/)
- [Request acess](https://llama.meta.com/llama-downloads/)
- [Meta Llama Model card](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3)
- [Kaggle meta](https://www.kaggle.com/organizations/metaresearch/models)

## âš¡ï¸ Cloud API 
### API í˜¸ì¶œ ê°€ëŠ¥
| ì´ë¦„ | ì„¤ëª… | ë§í¬ |
|------------|------|------|
| Grok | ê³ ì„±ëŠ¥ AI Chipì„ í†µí•´ LLaMA3ë¥¼ ì¸í¼ëŸ°ìŠ¤ ë° API í˜¸ì¶œì„ í†µí•´ ì´ìš©í•  ìˆ˜ ìˆë‹¤ | [Grok](https://console.groq.com/playground) | 
| AWS | bedrock ì—ì„œ LLaMAë¥¼ ì§€ì›í•©ë‹ˆë‹¤ í˜„ì¬ llama2ë§Œ ì‚¬ìš©ê°€ëŠ¥ |[AWS](https://aws.amazon.com/ko/bedrock/) |
| Azure | Microsoft Azure 8B/70B ë‘˜ë‹¤ ì§€ì› Azrue Marketplace ê²€ìƒ‰ | [Azure](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-8b-chat-offer?tab=overview)|
| together.ai | llama2, codellama, llama3 8b/70b inst ì‚¬ìš©ê°€ëŠ¥ |[together.ai](https://www.together.ai/) |


## ğŸ¤– ì¸í¼ëŸ°ìŠ¤ (Inference)


### ì¸í¼ëŸ°ìŠ¤ í”Œë«í¼
| í”Œë«í¼ ì´ë¦„ | ì„¤ëª… | ë§í¬ |
|------------|------|------|
| HuggingFace | Llama 8B | [link](https://meta-llama/Meta-Llama-3-8B) |
| HuggingFace | Llama 70B | [link](https://huggingface.co/meta-llama/Meta-Llama-3-70B) |
| HuggingFace | Llama 8B Instruct| [link](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) |
| HuggingFace | Llama 70B Instruct| [link](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) |
| HuggingFace | Llama Guard-2-8B(ì •ì±…ëª¨ë¸) | [link](https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B) |
| Ollama | ë‹¤ì–‘í•˜ê²Œ ê²½ëŸ‰í™” ë˜ì–´ìˆëŠ” llama3 ëª¨ë¸ ì¶”ë¡  ê°€ëŠ¥ | [link](https://ollama.com/library/llama3) |

## ğŸ’¬ Chat InterFace (Related Information)
| ì´ë¦„ | ë§í¬ |
|------------|------|
| HuggingChat | [link](https://huggingface.co/chat/) |
| Groq | [link](https://groq.com/) |
| togeter.ai |[link](https://www.together.ai/) |


## LLaMA Framework(RAG)

| ì´ë¦„ | ë§í¬ | 
|------------|------|
|Langchain | [link](https://www.langchain.com/) |
|llamaindex | [link](https://www.llamaindex.ai/) |


## ğŸ› ï¸ íŒŒì¸íŠœë‹ (Fine-tuning)
| ì´ë¦„ | ë§í¬ | 
|------------|------|
|torchrune| [link](https://github.com/pytorch/torchtune)|






## ê´€ë ¨ì •ë³´
| ì •ë³´ | ë§í¬ | 
|------------|------|
| í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ | [link](https://www.promptingguide.ai/tools)|
| ë§¥ë¶ê´€ë ¨ llama íŠœë‹ ë° ì¸í¼ëŸ°ìŠ¤ | [link](https://itnext.io/step-by-step-guide-to-running-latest-llm-model-meta-llama-3-on-apple-silicon-macs-m1-m2-or-m3-b9424ada6840) | 




## MAC vs 4090

| í•­ëª©          | M3 Max                              | M1 Pro                    | RTX 4090                                    |
|---------------|-------------------------------------|---------------------------|---------------------------------------------|
| CPU ì½”ì–´      | 16ì½”ì–´                              | 10ì½”ì–´                    | 16ì½”ì–´ AMD                                  |
| ë©”ëª¨ë¦¬        | 128GB                               | 16GB                      | 32GB                                        |
| GPU ë©”ëª¨ë¦¬    | ì—†ìŒ                                | ì—†ìŒ                      | 24GB                                        |
| **ëª¨ë¸ 7B** | - ëª¨ë“  ì»´í“¨í„°ì—ì„œ ì˜ ì‘ë™            | - ëª¨ë“  ì»´í“¨í„°ì—ì„œ ì˜ ì‘ë™   | - ëª¨ë“  ì»´í“¨í„°ì—ì„œ ì˜ ì‘ë™                    |
|               | - ì„±ëŠ¥ M3 Maxì™€ ìœ ì‚¬                  |                           | - ì„±ëŠ¥ M3 Maxì™€ ìœ ì‚¬                          |
| **ëª¨ë¸ 13B**| - ì„±ëŠ¥ ì¢‹ìŒ                        | - ì„¸ ë²ˆì§¸ë¡œ ì„±ëŠ¥ ì¢‹ìŒ       | - ê°€ì¥ ì„±ëŠ¥ ì¢‹ìŒ                             |
| **ëª¨ë¸ 70B**| - ë¹ ë¥´ê²Œ ì‹¤í–‰, 128GB ë©”ëª¨ë¦¬ í™œìš©    | - 16GB ë¶€ì¡±, í¬ë˜ì‹œ ë° ì¬ë¶€íŒ… | - GPUì—ì„œ ì‹¤í–‰ ë¶ˆê°€, CPUì—ì„œ ë§¤ìš° ëŠë¦¬ê²Œ ì‹¤í–‰ |
| ì „ë ¥ ì†Œëª¨      | 65W                                |                           | 250-300W                                    |
| ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ | ìš°ìˆ˜ ($4600)                       |                           | ë¹„êµì  ë‚®ìŒ ($6000 for A6000 GPU)            |


## ğŸ™Œ ê¸°ì—¬í•˜ê¸°
ì´ ì €ì¥ì†Œì— ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? [Issues](https://github.com/your-github/LLaMA3_Recipes/issues)ì— ììœ ë¡­ê²Œ ì˜ê²¬ì„ ë‚¨ê¸°ê±°ë‚˜ Pull Requestë¥¼ ë³´ë‚´ì£¼ì„¸ìš”. ëª¨ë“  ì¢…ë¥˜ì˜ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

## ğŸ“© ë¬¸ì˜í•˜ê¸°
ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ í˜‘ë ¥ì„ í¬ë§í•˜ì‹œëŠ” ë¶„ì€ [ì—¬ê¸°](https://github.com/your-github/LLaMA3_Recipes)ë¥¼ í´ë¦­í•˜ì—¬ ì €ì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”. í•¨ê»˜ ì§€ì‹ì„ ë‚˜ëˆ„ê³  ì‹¶ìŠµë‹ˆë‹¤!
